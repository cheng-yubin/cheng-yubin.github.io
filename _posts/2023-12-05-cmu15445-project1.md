---
title: CMU15445 Project1 总结
date: 2023-12-04 22:41:00 +0800
categories: [CMU15445]
tags: [CMU15445]
pin: true
---

## 一、 Project1 任务说明
CMU15445(Fall 2022)的[Project 1](https://15445.courses.cs.cmu.edu/fall2022/project1/)是在面向磁盘的存储管理器中实现一个缓冲池来缓存物理页面，使得DBMS支持大于内存可用量的数据库。在存储管理器中，需要实现以下三个组件：
1. Extendible Hash Table  
2. LRU-K Replacement Policy
3. Buffer Pool Manager Instance  

其中，可扩展哈希表用于在缓冲池管理器中维护Page ID和Frame ID之间的映射关系，LRU-K替换算法用于跟踪放置在各个页框中的页面的访问记录，并在需要时用于选择哪个页框中的页面被替换。

### Extendible Hash Table
[可扩展哈希表](https://15445.courses.cs.cmu.edu/fall2022/slides/07-hashtables.pdf)要求实现一个通用的哈希表，使用无序的桶（Bucket）来存储唯一键值对，支持插入、删除、查找功能。随着插入的数据增多，要求哈希表能够自动扩容，但不要求实现缩小功能。

可扩展哈希可以视为链式哈希的改进。链式哈希在哈希表的每个位置上维护一个链表（桶），哈希到这个位置的键值对被简单地插入到链表中。可扩展哈希在某个位置的链表过长时对哈希表进行扩容，然后拆分该链表，从而避免链表过长时降低哈希表性能。

可扩展哈希表由一个数组表示，元素为指向桶的指针。哈希表长度由Global Depth决定。例如，当Global Depth为2时，表示Hash(Key)的末尾2位有效，那么vector的长度为4，每个元素分别表示末尾为（00, 01, 10, 11）的情况。类似地，桶也有Local Depth属性，假设（00）指向的桶的Local Depth为1，那么表明Hash(Key)的最后1位有效，即哈希值最后一位为0的键值对应当放在该桶中，也就是说，位置（00, 10）对应的指针都应当指向该桶。

在这个例子中，当（00, 01）对应的这个桶满了时，需要将其拆分为两个桶。此时（00）,（01）各自指向独立的、Local Depth为2的Bucket，原先的键值对按照哈希值的末两位分别划分到两个桶中。

一次拆分后，可能的情况是（00）指向的桶依旧是满的，此时该桶的Local Depth与Glocal Depth相等，因此需要将哈希表扩容一倍。扩容后，Global Depth为3，位置（000，100）指向同一个桶。此时再将（000）指向的桶进行拆分。如此循环，直到所有桶均不满为止。

可扩展哈希的实现较为直接，按照算法流程实现即可，主要数据结构如下：
```cpp
class Bucket {
   size_t size_;        // Bucket最大容量
   int depth_;          // Local depth

   size_t curr_size_;   // Number of KV pairs in bucket
   std::vector<std::pair<K, V>> vec_;
};

class ExtendibleHashTable {
   int global_depth_;    // Global depth 
   size_t bucket_size_;  // Size of Bucket
   int num_buckets_;     // The number of buckets in the hash table

   mutable std::mutex latch_;
   std::vector<std::shared_ptr<Bucket>> dir_;  // The directory of the hash table
};
```

掉过的坑记录如下：  
1. 桶拆分时，需要修改多个哈希表位置的指针：  
   例如，global depth为3，（000, 010, 100, 110）均指向桶0，此时桶0需要拆分桶00和桶10，那么需要修改指针的位置包括（010, 110）,而不是只有（010）。

可学习的点记录如下：
1. std::hash 的使用；移位生成mask，并用与运算获取有效位
2. std::scoped_lock 的使用，将RAII（资源获取即初始化）思想用于std::mutex

### LRU-K Replacement Policy
[LRU-K算法](https://15445.courses.cs.cmu.edu/fall2022/slides/06-bufferpool.pdf)组件负责跟踪缓冲池中页面的使用情况。LRU-K算法是对LRU算法的改进，其中K是预定的常量。对于访问次数小于K次的页面，按照LRU规则进行替换，即最近刚被访问过的页面后替换，最久没被访问的页面先替换；对于访问次数大于等于K次的页面，按照倒数第K次访问的时间Tk进行替换，倒数第K次访问越久远，Tk越小，越先被替换。

LRU-K组件应当包含两方面功能：
1. 记录各个Frame的信息，包括是否可被替换、访问记录。
2. 维护替换次序。根据访问次数是否达到K次，可以分为访问队列、缓存队列分别进行维护。访问队列根据最近一次访问时间进行排序，缓存队列以倒数第K次访问时间进行排序。

LRU-K组件的主要挑战在于数据结构的选择：
1. 对于Frame信息的记录，由于Frame数量固定，可以将Frame信息打包为一个类，使用vector进行管理。
2. 对于访问队列，使用哈希表+链表表示。查找、删除、尾部插入的复杂度均为O(1).
3. 对于缓存队列，使用红黑树表示。查找、删除、有序插入的复杂度均为O(logn).

主要数据结构如下：
```cpp
class FrameStatus {
   frame_id_t frame_id_;   // Frame id
   const size_t k_;        // K
   size_t access_cnt_;     // Times of the frame been accessed
   bool evictable_;        // evictable or not

   std::vector<size_t> hist_; // Circular queue for access history
   int32_t curr_;

   // iterator point to visit list node 
   // in order to find / erase from visit list by O(1)
   std::optional<std::list<FrameStatus *>::iterator> iter_visit_op_;
};

class LRUKReplacer {
   std::list<FrameStatus *> frames_visit_;               // visit list
   std::set<FrameStatus *, CmpTimeStamp> frames_cache_;  // cache list

   size_t curr_size_;      // Number of evictable frames
   size_t replacer_size_;  // Maximum number of the frames allowed
   size_t k_;              // K
   size_t curr_timestamp_; // Logical timestamp

   std::vector<FrameStatus> frame_info_;  // Status of each Frames
   std::mutex latch_;
};
```

掉过坑记录如下：
1. 页面每被访问一次，访问时的TimeStamp被加入到访问历史中。这里的Timestamp只需要区分访问的先后，无关真实时间，因此只需要逻辑时间戳，不需要向操作系统获取真实时间戳！不然很慢很慢很慢！
2. 没有被使用的页框，不应当被设置为Evictable！（没有被使用，没有访问记录，能按照什么插入队列呢？）

可学习的点记录如下：
1. 根据操作复杂度选取合适的数据结构。
2. std::set 的使用；红黑树原理。

### Buffer Pool Manager Instance
缓冲池管理器负责管理缓存在内存中数据库页面，主要功能如下：
1. 提供多个页框用于缓存数据库页面，并管理页面状态，包括引用计数、是否为脏
2. 维护数据库页面号与页框号之间的映射关系
3. 空闲页框消耗完后，利用LRU-K组件选择替换的页框，并将被替换的脏页写回磁盘。

主要数据结构如下：
```cpp
class Page {
  char data_[4096]{};         // Actual data stored within a page.
  page_id_t page_id_;         // ID of this page
  int pin_count_ = 0;         // Pin count of this page
  bool is_dirty_ = false;     // Dirty flag
  ReaderWriterLatch rwlatch_;
};

class BufferPoolManagerInstance {
  Page *pages_;                        // Array of buffer pool pages
  DiskManager *disk_manager_;          // Disk manager
  ExtendibleHashTable<page_id_t, frame_id_t> *page_table_;  // Page table
  LRUKReplacer *replacer_;             // LRU-K  
  std::vector<frame_id_t> free_list_;  // Free pages
  std::mutex latch_;
};
```
掉过的坑记录：
1. 记录空闲页框的数据结构free_list名为list，但最大长度固定且已知，只有尾部插入删除操作，使用vector更为合适。

可学习的点：
1. 页框类Page的实现
2. 磁盘交互DiskManager的实现。

## 二、性能优化
第一次完成Project1并通过全部线上测试时，只关注了功能实现，完全忽视了代码的运行性能，因此Leadboard任务直接超时，没有排名。因此，后来有回过头对Project1进行性能优化，这里对关键的几个优化点简要记录。

1. **使用逻辑时间戳而非真实时间戳**  
   第一次实现时，看到“Timestamp”就选择向操作系统查询当前时间，为了区别不同访问的先后顺序，时间戳精度还得选择纳秒，直接导致了运行超时。实际上，时间戳仅用于区分访问先后，无关真实时间，仅需要一个自增的原子变量即可。修正后Leadboard任务由超时提升到9s.

2. **LRU-K淘汰队列的数据结构选择**  
   从LRU推广到LRU-K算法的过程中，没有思考新增加的缓存队列与访问队列的功能区别，就直接照搬了LRU的哈希表+队列数据结构。事实上，缓存队列需要有序插入，而访问队列仅需要尾部插入，两者有本质不同。对于访问队列，哈希表+队列可以实现O(1)的查找、删除、尾部插入，因此保留；对于缓存队列，插入的时间复杂度为O(n)，因此将数据结构改为红黑树，实现O(logn)的查找、删除、插入。此外，访问队列中的哈希表可以进一步优化。哈希表的key是各个页框的ID，为0~N-1的整数，因此可以由一个vector替代，或者整合进入FrameStaus数据结构中，节省了哈希表的消耗。

3. **预先分配足够内存空间**  
   对于FrameStatus，由于总数固定，使用vector而不是unorder_map进行管理；对于页面的访问记录，由于最多记录K次历史访问，使用长度为K的vector建立循环队列，而不是使用list进行存储。

由于经验不足，对Project1的性能优化花费了三天时间，其中大部分时间都在试图找到可能的优化的点。回顾性能优化过程，发现走了很多弯路，浪费了很多时间。总结两点经验：  
1. 根据数据的特点（总数固定）和对数据的操作（查找、插入、删除、排序等）选择恰当的数据结构。时间复杂度首先决定了代码的运行性能。
2. 空间换时间，提前分配足够的内存空间，减少内存分配次数。

经过几天的努力，Project1的Leaderborad任务从超时优化到1.9s，有了明显进步，记录如下。

![grade](/assets/img/2023-12-05-cmu15445-project1/grade.png)